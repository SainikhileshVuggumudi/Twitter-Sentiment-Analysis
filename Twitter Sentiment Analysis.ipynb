{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**problem Statement**:Sentiment Analysis- Need to analyse  \"people opinion about work from home during lock down\" and get the sentiment score using Sentiwordnet from python by using webscraping to get tweets from twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import string\n",
    "import time\n",
    "import csv\n",
    "import json\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy.streaming import StreamListener\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tag.mapping import map_tag\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets Extracting using \"Twitter API\"\n",
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    We create a TwitterClient class. This class contains all the methods to interact with Twitter API and parsing tweets. \n",
    "    We use __init__ function to handle the authentication of API client.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        \n",
    "        # __init__ is the constructor for a class. The self variable represents the instance of the object itself.\n",
    "        # When a class defines an __init__() method, class instantiation automatically invokes __init__() for the newly-created class instance. \n",
    "        \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        \n",
    "        consumer_key = 'I5EQI9SZPHbzHU1NY1KK3C2qx'\n",
    "        consumer_secret = 'OOsThzGqX1niE9YN6hPwoTG9Q4u5rij3mqsIuOwg9VsZve5LYR'\n",
    "        access_token = '147830710-w3n86zZ3f69z9xX8XfACEKAlCq8uRaFU7lFVGBM6'\n",
    "        access_token_secret = '9oTYADmKqvPXLH5pnO9tP3pBlN6mmAZEAbDn0kPAOznSD'\n",
    "        \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "\n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "  \n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return(' '.join(re.sub(\"([,\\.():;!$%^&*\\d])|([^0-9A-Za-z \\t])\", \" \", tweet).split())) \n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return('positive')\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return ('neutral')\n",
    "        else: \n",
    "            return ('negative')\n",
    "  \n",
    "    def get_tweets(self, query, count = 100): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "        \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "              \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                parsed_tweet['date'] = tweet.created_at\n",
    "                \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return (tweets) \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'work from while lock down', count = 1500) \n",
    "    \n",
    " \n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} % \".format(100*(len(tweets) - (len(ntweets) + len(ptweets)))/len(tweets))) \n",
    "  \n",
    "    # printing first 10 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text'])\n",
    "        # print(tweet['date'])\n",
    "  \n",
    "    # printing first 10 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text'])\n",
    "        # print(tweet['date'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 68.75 %\n",
      "Negative tweets percentage: 21.875 %\n",
      "Neutral tweets percentage: 9.375 % \n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "@GlennBBC @BBCScotlandNews @NicolaSturgeon great we hold construction back from returning to work yet let people go… https://t.co/kTTZ4za6AR\n",
      "@frink_caleb a true FS/SS mixing it up getting in some lock down corner work while taking a break from studying for… https://t.co/N7m0jNrYHE\n",
      "RT @adamugarba: With @Crater365NG , we have been doing an excellent job by helping our customers across industries to work, even while on l…\n",
      "@AndrewBatesNC Love it the left can’t stand it as they just run their mouths&amp; are the so nothing Dems as they can’t… https://t.co/hF9i1ZUy6n\n",
      "RT @adamugarba: With @Crater365NG , we have been doing an excellent job by helping our customers across industries to work, even while on l…\n",
      "RT @hubforsuccess: My daughter is sitting opposite me while I work- home schooling herself on aquatic mammals via the brilliant and free @O…\n",
      "RT @hubforsuccess: My daughter is sitting opposite me while I work- home schooling herself on aquatic mammals via the brilliant and free @O…\n",
      "RT @hubforsuccess: My daughter is sitting opposite me while I work- home schooling herself on aquatic mammals via the brilliant and free @O…\n",
      "RT @adamugarba: With @Crater365NG , we have been doing an excellent job by helping our customers across industries to work, even while on l…\n",
      "With @Crater365NG , we have been doing an excellent job by helping our customers across industries to work, even wh… https://t.co/sVvGg9JEKX\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "@greedstinks @bryang_KR @carlquintanilla Getting back to work will save small businesses &amp; poor people from going b… https://t.co/3uAveCeO2Z\n",
      "@elisecterry I had to set a timer lock on my phone to keep me from falling down Twitter comment rabbit holes while… https://t.co/IlpF0mdFCO\n",
      "The lock down has been extended for the next 14 days that is us who where told to work in today's presidential addr… https://t.co/KBOtpHbEgO\n",
      "@HMRCcustomers how long are people allowed to work from abroad? e.g. I'm working from home at the moment, if I deci… https://t.co/4Jfm9EuDhJ\n",
      "*Don't take tension, I have nothing.  There was no need to go somewhere in the lock-down for 21 days, so while retu… https://t.co/HUmGMgeFUI\n",
      "@RealJamesWoods SanFran Nan face work done while on Vacay, while we were all on lock down - that's ointment for the… https://t.co/U5qNny2Cnw\n",
      "@davidmcw why is Paschal D harping on about the cost of the lock down costing €30 bill, he should listen to the Dav… https://t.co/tyLDqfGFdt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"@HMRCcustomers how long are people allowed to work from abroad? e.g. I'm working from home at the moment, if I deci… https://t.co/4Jfm9EuDhJ\",\n",
       "  'date': datetime.datetime(2020, 5, 18, 12, 58, 3),\n",
       "  'sentiment': 'negative'},\n",
       " {'text': 'RT @hubforsuccess: My daughter is sitting opposite me while I work- home schooling herself on aquatic mammals via the brilliant and free @O…',\n",
       "  'date': datetime.datetime(2020, 5, 15, 16, 46, 30),\n",
       "  'sentiment': 'positive'},\n",
       " {'text': 'RT @hubforsuccess: My daughter is sitting opposite me while I work- home schooling herself on aquatic mammals via the brilliant and free @O…',\n",
       "  'date': datetime.datetime(2020, 5, 15, 15, 22, 15),\n",
       "  'sentiment': 'positive'},\n",
       " {'text': 'RT @hubforsuccess: My daughter is sitting opposite me while I work- home schooling herself on aquatic mammals via the brilliant and free @O…',\n",
       "  'date': datetime.datetime(2020, 5, 15, 14, 18, 25),\n",
       "  'sentiment': 'positive'},\n",
       " {'text': 'RT @hubforsuccess: My daughter is sitting opposite me while I work- home schooling herself on aquatic mammals via the brilliant and free @O…',\n",
       "  'date': datetime.datetime(2020, 5, 15, 12, 9, 35),\n",
       "  'sentiment': 'positive'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating object of TwitterClient Class\n",
    "api = TwitterClient()\n",
    "   \n",
    "# calling function to get tweets\n",
    "api_tweets = api.get_tweets(query = 'work from home while lock down', count = 1000) \n",
    "\n",
    "api_tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets Extracting using \"GetOldTweets3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting GetOldTweets3\n",
      "  Downloading https://files.pythonhosted.org/packages/ed/f4/a00c2a7c90801abc875325bb5416ce9090ac86d06a00cc887131bd73ba45/GetOldTweets3-0.0.11-py3-none-any.whl\n",
      "Requirement already satisfied: lxml>=3.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from GetOldTweets3) (4.3.4)\n",
      "Collecting pyquery>=1.2.10 (from GetOldTweets3)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/43/95d42e386c61cb639d1a0b94f0c0b9f0b7d6b981ad3c043a836c8b5bc68b/pyquery-1.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: cssselect>0.7.9 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n",
      "Installing collected packages: pyquery, GetOldTweets3\n",
      "Successfully installed GetOldTweets3-0.0.11 pyquery-1.4.1\n"
     ]
    }
   ],
   "source": [
    "#installation\n",
    "!pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got\n",
    "text_query = 'work from home while lock down'\n",
    "since_date = '2020-03-20'\n",
    "until_date = '2020-05-21'\n",
    "count = 2500\n",
    "# Creation of query object\n",
    "tweetCriteria = got.manager.TweetCriteria().setQuerySearch(text_query).setSince(since_date).setUntil(until_date).setMaxTweets(count)\n",
    "# Creation of list that contains all tweets\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "# Creating list of chosen tweet data\n",
    "tweets_text = [[tweet.date, tweet.text] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.datetime(2020, 5, 20, 21, 51, 10, tzinfo=datetime.timezone.utc),\n",
       " 'Haven’t seen these guys since 18th March . Hope they are keeping well in lockdown in my office. With being able to work from home it might be a while before I see them ']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transforming into Dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfh_tweets = pd.DataFrame(tweets_text, columns = ['Datetime', 'Tweets_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweets_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-20 21:51:10+00:00</td>\n",
       "      <td>Haven’t seen these guys since 18th March . Hop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-20 19:33:29+00:00</td>\n",
       "      <td>Sweden is unlikely to avoid the economic fallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-20 19:30:19+00:00</td>\n",
       "      <td>Greece practiced a strict lockdown and we were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-20 19:09:15+00:00</td>\n",
       "      <td>Also the majority of who are infected are elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-20 18:25:02+00:00</td>\n",
       "      <td>While the lockdown, work from home might look ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime                                        Tweets_text\n",
       "0 2020-05-20 21:51:10+00:00  Haven’t seen these guys since 18th March . Hop...\n",
       "1 2020-05-20 19:33:29+00:00  Sweden is unlikely to avoid the economic fallo...\n",
       "2 2020-05-20 19:30:19+00:00  Greece practiced a strict lockdown and we were...\n",
       "3 2020-05-20 19:09:15+00:00  Also the majority of who are infected are elde...\n",
       "4 2020-05-20 18:25:02+00:00  While the lockdown, work from home might look ..."
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfh_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverting uppercase words to lowercase in the tweets\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].apply(lambda x: \" \".join(x.lower() for x in x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing mail id's from the tweets\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].str.replace(\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+\", \"\")\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].str.replace(\"<@[a-zA-Z0-9-]+.[a-zA-Z0-9-.]+.[a-zA-Z0-9-.]+\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the usernames from the tweets\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].str.replace('@[A-Z0-9a-z_:]+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the links from the tweets\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].str.replace(\"https?://(www.)?\\w+\\.\\w+(/\\w+)*/?\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the 'RT' tag from the tweets\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].str.replace('^[RT]+','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-letters from the text\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].str.replace(\"[^a-zA-Z]\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove extra spaces from the text\n",
    "wfh_tweets['Tweets_text'] = wfh_tweets['Tweets_text'].str.replace(\"\\s\\s+\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweets_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-20 21:51:10+00:00</td>\n",
       "      <td>haven t seen these guys since th march hope th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-20 19:33:29+00:00</td>\n",
       "      <td>sweden is unlikely to avoid the economic fallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-20 19:30:19+00:00</td>\n",
       "      <td>greece practiced a strict lockdown and we were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-20 19:09:15+00:00</td>\n",
       "      <td>also the majority of who are infected are elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-20 18:25:02+00:00</td>\n",
       "      <td>while the lockdown work from home might look e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime                                        Tweets_text\n",
       "0 2020-05-20 21:51:10+00:00  haven t seen these guys since th march hope th...\n",
       "1 2020-05-20 19:33:29+00:00  sweden is unlikely to avoid the economic fallo...\n",
       "2 2020-05-20 19:30:19+00:00  greece practiced a strict lockdown and we were...\n",
       "3 2020-05-20 19:09:15+00:00  also the majority of who are infected are elde...\n",
       "4 2020-05-20 18:25:02+00:00  while the lockdown work from home might look e..."
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfh_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identify the sentiment using Sentiwordnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = PorterStemmer()\n",
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pos_senti(wfh_tweets):\n",
    "    li_swn=[]\n",
    "    li_swn_pos=[]\n",
    "    li_swn_neg=[]\n",
    "    missing_words=[]\n",
    "    for i in range(len(wfh_tweets.index)):\n",
    "        text = wfh_tweets.loc[i]['Tweets_text']\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        tagged_sent = pos_tag(tokens)\n",
    "        store_it = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in tagged_sent]\n",
    "        #print(\"Tagged Parts of Speech:\",store_it)\n",
    "\n",
    "        pos_total=0\n",
    "        neg_total=0\n",
    "        for word,tag in store_it:\n",
    "            if(tag=='NOUN'):\n",
    "                tag='n'\n",
    "            elif(tag=='VERB'):\n",
    "                tag='v'\n",
    "            elif(tag=='ADJ'):\n",
    "                tag='a'\n",
    "            elif(tag=='ADV'):\n",
    "                tag = 'r'\n",
    "            else:\n",
    "                tag='nothing'\n",
    "\n",
    "            if(tag!='nothing'):\n",
    "                concat = word+'.'+tag+'.01'\n",
    "                try:\n",
    "                    this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                    this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                    #print(word,tag,':',this_word_pos,this_word_neg)\n",
    "                except Exception as e:\n",
    "                    wor = lem.lemmatize(word)\n",
    "                    concat = wor+'.'+tag+'.01'\n",
    "                    # Checking if there's a possiblity of lemmatized word be accepted into SWN corpus\n",
    "                    try:\n",
    "                        this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                        this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                    except Exception as e:\n",
    "                        wor = st.stem(word)\n",
    "                        concat = wor+'.'+tag+'.01'\n",
    "                        # Checking if there's a possiblity of lemmatized word be accepted\n",
    "                        try:\n",
    "                            this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                            this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                        except:\n",
    "                            missing_words.append(word)\n",
    "                            continue\n",
    "                pos_total+=this_word_pos\n",
    "                neg_total+=this_word_neg\n",
    "        li_swn_pos.append(pos_total)\n",
    "        li_swn_neg.append(neg_total)\n",
    "\n",
    "        if(pos_total!=0 or neg_total!=0):\n",
    "            if(pos_total>neg_total):\n",
    "                li_swn.append(1)\n",
    "            else:\n",
    "                li_swn.append(-1)\n",
    "        else:\n",
    "            li_swn.append(0)\n",
    "    wfh_tweets.insert(5,\"pos_score\",li_swn_pos,True)\n",
    "    wfh_tweets.insert(6,\"neg_score\",li_swn_neg,True)\n",
    "    wfh_tweets.insert(7,\"sent_score\",li_swn,True)\n",
    "    return wfh_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Tweets_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-20 21:51:10+00:00</td>\n",
       "      <td>haven t seen these guys since th march hope th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-20 19:33:29+00:00</td>\n",
       "      <td>sweden is unlikely to avoid the economic fallo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-20 19:30:19+00:00</td>\n",
       "      <td>greece practiced a strict lockdown and we were...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-20 19:09:15+00:00</td>\n",
       "      <td>also the majority of who are infected are elde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-20 18:25:02+00:00</td>\n",
       "      <td>while the lockdown work from home might look e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Datetime                                        Tweets_text\n",
       "0 2020-05-20 21:51:10+00:00  haven t seen these guys since th march hope th...\n",
       "1 2020-05-20 19:33:29+00:00  sweden is unlikely to avoid the economic fallo...\n",
       "2 2020-05-20 19:30:19+00:00  greece practiced a strict lockdown and we were...\n",
       "3 2020-05-20 19:09:15+00:00  also the majority of who are infected are elde...\n",
       "4 2020-05-20 18:25:02+00:00  while the lockdown work from home might look e..."
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wfh_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 1904\n",
      "Total tweets with sentiment: 1904\n",
      "positive tweets: 1118\n",
      "negative tweets: 498\n",
      "neutral tweets: 288\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "count_total=0\n",
    "count_pos=0\n",
    "count_neg=0\n",
    "count_neut=0\n",
    "\n",
    "li_tb = []\n",
    "for i in range(len(wfh_tweets.index)):\n",
    "    sent = TextBlob(str(wfh_tweets.loc[i]['Tweets_text']))\n",
    "    if(sent.sentiment.polarity>0):\n",
    "        count_pos=count_pos+1\n",
    "        count_total=count_total+1\n",
    "        li_tb.append(1)\n",
    "    elif(sent.sentiment.polarity<0):\n",
    "        count_neg=count_neg+1\n",
    "        count_total=count_total+1\n",
    "        li_tb.append(-1)\n",
    "    else:\n",
    "        li_tb.append(0)\n",
    "        count_neut+=1\n",
    "\n",
    "        count_total=count_total+1\n",
    "\n",
    "\n",
    "#  print(df.loc[i]['full_text'])\n",
    "#  print(sent.sentiment)\n",
    "print(\"Total tweets:\",len(wfh_tweets.index))\n",
    "print(\"Total tweets with sentiment:\",count_total)\n",
    "print(\"positive tweets:\",count_pos)\n",
    "print(\"negative tweets:\",count_neg)\n",
    "print(\"neutral tweets:\",count_neut)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
